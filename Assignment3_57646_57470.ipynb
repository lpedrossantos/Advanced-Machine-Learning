{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b3b739d",
   "metadata": {},
   "source": [
    "### Exercício de modelos mistos -- Problem 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed0c01c",
   "metadata": {},
   "source": [
    "#### Beltrán Liniers  nº57646\n",
    "\n",
    "#### Luís Santos nº57470"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9d736a",
   "metadata": {},
   "source": [
    "No presente trabalho será abordado modelos mistos. Estes consistem numa combinação de diferentes modelos de classificação, denominados de experts, para realizarem o processo de previsão [1].\n",
    "O dataset é composto por 30 variáveis independentes e 569 observações. Sendo a target variable binária que indica se possuí cancro da mama ou não. \n",
    "Inicia-se com a definição de uma série de funções que vão ajudar a automatizar os processos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4266b15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import train_test_split,cross_validate\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63aa5dfd",
   "metadata": {},
   "source": [
    "### Functions definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0dcaea8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    data = load_breast_cancer()\n",
    "    X = data.data\n",
    "    y = data.target\n",
    "    features = data.feature_names\n",
    "    target = data.target_names\n",
    "    return X,y,features,target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "42a3bbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(X,y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.33,random_state=12)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91400a50",
   "metadata": {},
   "source": [
    "No processo todo de classificação serão utilizados três conjuntos de dados vindos do mesmo dataset inicial: train, validation e test. Este conjunto train será utilizado para treinar o modelo. Posteriormente, os dados de validação serão usados para calcular os accuracy de cada expert, os quais vão ser usados para criar as ponderações com a função softmax. Finalmente, o conjunto de test será utilizado para predizer e calcular o accuracy final.\n",
    "\n",
    "Previamente é necessário realizar uma standardização dos dados, devido à grande diferença entre as medidas das features. Esta normalização será feita no conjunto de treino. Posteriormente, no momento de uso do validation set e test set, estes também serão normalizados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4518adf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, features, target = load_data()\n",
    "X_train,X_test,y_train,y_test = preprocess_data(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c8c742",
   "metadata": {},
   "source": [
    "A função `train test models` permite testar uma serie de modelos, onde os Accuracy scores de cada modelo serão utilizados para calcular uma média ponderada. Esta é multiplicada pelos outputs dos modelos. A este resultado obtido é aplicado a função `round` obtendo assim uma matriz com valores binários de 0 e 1. \n",
    "\n",
    "Ao se utilizar os accuracy para calcular esta média, está-se a concluir que se terão modelos con maior capacidade de classificação e importância que outros. Pelo que, num sistema de votação estes terão um maior peso de voto, no label a atribuir ao exemplo [2]. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7c7915d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_models(experts,X,y):\n",
    "    scores = []\n",
    "    y_preds = None\n",
    "    X_train,X_validation,y_train,y_validation = train_test_split(X,y,test_size=0.33,random_state=12)\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    \n",
    "    for expert in experts:\n",
    "        expert.fit(X_train,y_train)\n",
    "        X_validation = scaler.transform(X_validation)\n",
    "        \n",
    "        score = expert.score(X_validation,y_validation)\n",
    "        scores.append(score)\n",
    "    return scores\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1f73f159",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_avg_ensemble(experts,scores,X_test):\n",
    "    y_preds = None\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_test)\n",
    "    for expert in experts:\n",
    "        X_test = scaler.transform(X_test)\n",
    "        y_pred = [expert.predict(X_test)]\n",
    "        if y_preds is None:\n",
    "            y_preds = y_pred\n",
    "        else:\n",
    "            y_preds = np.concatenate((y_preds,y_pred))\n",
    "    \n",
    "    output = np.round(np.dot(softmax(scores),y_preds))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0857b8d6",
   "metadata": {},
   "source": [
    "Por outro lado, a função `expert_optimizer` encontra a melhor combinação de modelos expert a ser testados, assim como o número ótimo deles que maximizam o accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c7d43ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expert_optimizer(experts_list,X_train,X_test,y_train,y_test,num_experts = 2):\n",
    "    \n",
    "    scores_arr = []\n",
    "    j=0\n",
    "    while j <= (len(experts_list)-num_experts):\n",
    "        scores = train_test_models(experts_list[j:j+num_experts], X_train, y_train)\n",
    "        output_preds = weighted_avg_ensemble(experts_list[j:j+num_experts],scores,X_test)\n",
    "        new_acc = accuracy_score(y_test,output_preds)\n",
    "        scores_arr.append({'acc':new_acc,'experts':experts_list[j:j+num_experts]})\n",
    "        j+=num_experts\n",
    "    df_scores = pd.DataFrame(scores_arr)\n",
    "    #print(df_scores)\n",
    "    return df_scores.loc[df_scores['acc']==df_scores['acc'].max()]\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47afd51e",
   "metadata": {},
   "source": [
    "##### Experts Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7702043",
   "metadata": {},
   "source": [
    "O primeiro teste vai ser uma combinação de duas árvores de decisão, com a diferença no híperparâmetro *criterion*: gini e entrópia. Como output da função `train_test_models` obteve-se a matriz com valores binários que corresponde aos labels obtidos com a *Weighted Average Ensemble*. \n",
    "\n",
    "A Accuracy obtida co o conjunto de teste é superior a 0.88."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f7c962e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
       "       0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
       "       0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,\n",
       "       1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1.,\n",
       "       0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1.,\n",
       "       1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1.,\n",
       "       1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1.,\n",
       "       0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0.,\n",
       "       1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       0.])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = [DecisionTreeClassifier(criterion='gini'),DecisionTreeClassifier(criterion='entropy')]\n",
    "scores = train_test_models(models,X_train,y_train)\n",
    "output_DT = weighted_avg_ensemble(models,scores,X_test)\n",
    "output_DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8d3a9416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O accuracy com dois experts de decision tree é:  0.8882978723404256\n"
     ]
    }
   ],
   "source": [
    "print(\"O accuracy com dois experts de decision tree é: \", accuracy_score(y_test,output_DT))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730ae12c",
   "metadata": {},
   "source": [
    "##### Experts SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d48374d",
   "metadata": {},
   "source": [
    "Experimentou-se dois SVM’s como experts. Sendo que no primeiro expert foi definido um poly kernel de grau 2. E no segundo expert foi especificado um rbf kernel. O resultado obtido foi inferior ao accuracy conseguido com as Árvores de Decisão, sendo de 0.835."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8e5cbd44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1.,\n",
       "       0., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1.,\n",
       "       0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1.,\n",
       "       0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1.,\n",
       "       1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
       "       0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0.,\n",
       "       1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       0.])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = [SVC(kernel='poly', C=1, gamma=0.1, degree=2),SVC(kernel='rbf', C=1, gamma=0.1)]\n",
    "scores = train_test_models(models,X_train,y_train)\n",
    "output_SVM = weighted_avg_ensemble(models,scores,X_test)\n",
    "output_SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "014c6758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score with 2 experts both SVM:  0.8351063829787234\n"
     ]
    }
   ],
   "source": [
    "accuracy_score(y_test,output_SVM)\n",
    "print(\"Accuracy score with 2 experts both SVM: \", accuracy_score(y_test,output_SVM))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339eb32a",
   "metadata": {},
   "source": [
    "##### Experts Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f73162",
   "metadata": {},
   "source": [
    "Posteriormente, utilizou-se dois experts de Regressão logística, estes diferenciam-se pelo solver utilizado: liblinear e lbfgs.\n",
    "\n",
    "Foi obtida a accuracy mais elevada dos três ensemble models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "62584288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1.,\n",
       "       0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1.,\n",
       "       0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,\n",
       "       1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1.,\n",
       "       0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1.,\n",
       "       1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1.,\n",
       "       1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1.,\n",
       "       0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0.,\n",
       "       1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
       "       0.])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = [LogisticRegression(solver='liblinear', C=1, max_iter=5000), LogisticRegression(solver='lbfgs', C=1,max_iter=5000)]\n",
    "scores = train_test_models(models,X_train,y_train)\n",
    "output_LR = weighted_avg_ensemble(models,scores,X_test)\n",
    "output_LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1a9c3729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score with 2 experts both Logistic Regression:  0.9574468085106383\n"
     ]
    }
   ],
   "source": [
    "accuracy_score(y_test,output_LR)\n",
    "print(\"Accuracy score with 2 experts both Logistic Regression: \", accuracy_score(y_test,output_LR))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24bed8f",
   "metadata": {},
   "source": [
    "##### Combinação de Experts com diferente número de níveis e classes de modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462ff40f",
   "metadata": {},
   "source": [
    "Seguidamente, para efeitos de análise e comparação entre modelos, desenvolveu-se a função `expert_optimizer`, que encontra a melhor combinação de experts. \n",
    "\n",
    "No conjunto de dados utilizado, os melhores resultados foram obtidos, de forma clara, com ambos modelos da regressão logística. Como tal, decidiu-se não incorporá-los no conjunto de experts a testar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "41bf515e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        acc                                            experts\n",
      "0  0.930851  [DecisionTreeClassifier(ccp_alpha=0.0, class_w...\n"
     ]
    }
   ],
   "source": [
    "models = [DecisionTreeClassifier(criterion='gini'), \n",
    "          DecisionTreeClassifier(criterion='entropy'), \n",
    "          SVC(kernel='poly', C=1, gamma=0.1, degree=2),\n",
    "          SVC(kernel='rbf', C=1, gamma=0.1)]\n",
    "\n",
    "optimal_model = expert_optimizer(models, X_train, X_test, y_train, y_test,3)\n",
    "print(optimal_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f8ee41",
   "metadata": {},
   "source": [
    "Assim, deste processo o melhor resultado obtido foi com os experts SVM com um rbf kernel e uma Árvore de Decisão com o critério de entropia. Tendo sido o accuracy score de 0.93."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0639ff72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                        max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "                        min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                        min_samples_leaf=1, min_samples_split=2,\n",
       "                        min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                        random_state=None, splitter='best'),\n",
       " DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',\n",
       "                        max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "                        min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                        min_samples_leaf=1, min_samples_split=2,\n",
       "                        min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                        random_state=None, splitter='best'),\n",
       " SVC(C=1, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "     decision_function_shape='ovr', degree=2, gamma=0.1, kernel='poly',\n",
       "     max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "     tol=0.001, verbose=False)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_model['experts'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c42f4e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A combinação ótima de experts é formada pelos modelos: [DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',\n",
      "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), SVC(C=1, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=2, gamma=0.1, kernel='poly',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)]\n",
      "\n",
      "O accuracy do modelo mixto ótimo é:  0.9308510638297872\n"
     ]
    }
   ],
   "source": [
    "print(\"A combinação ótima de experts é formada pelos modelos: {}\".format([optimal_model['experts'].values[0][i] for i in range(len(optimal_model['experts'].values[0]))]))\n",
    "print(\"\\nO accuracy do modelo mixto ótimo é: \", optimal_model['acc'].values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fad57b5",
   "metadata": {},
   "source": [
    "A principal vantagem dos modelos mistos é que possibilita o melhoramento da performance, em comparação a um modelo único. Como foi visto, com duas Árvores de Decisão obteve um accuracy de 0.88, e o modelo com dois SVM, 0.83. Mas com a combinação de ambos alcançou-se um accuracy score de 0.93.\n",
    "\n",
    "Por outro lado, não é uma técnica que garanta sempre melhores resultados, como foi observado com a combinação de duas Logistic Regression obteve-se o melhor accuracy score de todos os modelos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee0d4e2",
   "metadata": {},
   "source": [
    "#### References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3862f32d",
   "metadata": {},
   "source": [
    "[1] Ensemble Models. (2022). Retrieved 19 March 2022, from https://towardsdatascience.com/ensemble-models-5a62d4f4cb0c\n",
    "\n",
    "[2] Brownlee, J. (2022). How to Develop a Weighted Average Ensemble With Python. Retrieved 20 March 2022, from https://machinelearningmastery.com/weighted-average-ensemble-with-python/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
